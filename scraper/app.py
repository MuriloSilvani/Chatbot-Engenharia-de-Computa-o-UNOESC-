import requests
from bs4 import BeautifulSoup
import markdownify
import pdfplumber
import re
import os

OUTPUT_FILE = "../backend/ai/base_conhecimento.md"

PAGES = [
    "https://www.unoesc.edu.br/cursos/engenharia-de-computacao",
]

PDF_LINKS = [
    "https://www.unoesc.edu.br/cursos/wp-content/uploads/sites/2/2025/09/PPC-Engenharia-de-Computacao.pdf",
]

def clean_text(text):
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    return text

def fetch_html(url):
    print(f"üîé Extraindo p√°gina: {url}")
    html = requests.get(url, verify=False).text
    soup = BeautifulSoup(html, "html.parser")

    for tag in soup(["script", "style", "footer", "header", "nav"]):
        tag.decompose()

    main = soup.find("main") or soup.body
    text_html = str(main)

    markdown = markdownify.markdownify(text_html, heading_style="ATX")
    markdown = clean_text(markdown)
    return markdown

def fetch_pdf(url):
    resp = requests.get(url, stream=True, verify=False)
    fname = "temp.pdf"
    with open(fname, "wb") as f:
        f.write(resp.content)
    text = ""
    with pdfplumber.open(fname) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    os.remove(fname)
    return text.strip()

def fetch_ementario():
    print("üìò Buscando ement√°rio das disciplinas...")

    subjects_url = "https://www.unoesc.edu.br/cursos/wp-json/wst/v1/subjects?course_id=4788"
    ementario_url_template = "https://www.unoesc.edu.br/cursos/wp-json/wst/v1/ementario?course_id=4788&subject_id={}&campus_id=600"

    try:
        resp = requests.get(subjects_url, verify=False, timeout=10)
        data = resp.json()
    except Exception as e:
        print("‚ùå Erro ao obter disciplinas:", e)
        return ""

    if not data.get("status", False):
        print("‚ùå Resposta inv√°lida da API de subjects.")
        return ""

    subjects = data["data"]["subjects"]

    final_text = "## üìö Ement√°rio das Disciplinas\n\n"

    for subj in subjects:
        sid = subj["id"]
        title = subj["title"]
        credits = subj.get("credits")
        hours = subj.get("hours")
        fase = subj.get("codigoFase")

        print(f"üîé Extraindo ement√°rio: {title}")

        try:
            url = ementario_url_template.format(sid)
            r = requests.get(url, verify=False, timeout=10)
            ement = r.json()

            description = ement.get("data", {}).get("description", "Ement√°rio n√£o encontrado")
            description = clean_text(description)

        except Exception as e:
            description = f"Erro ao extrair ement√°rio: {e}"

        final_text += f"""
### üìò {title}

- Cr√©ditos: {credits}
- Carga hor√°ria: {hours}h
- Fase: {fase}

**Ement√°rio:**  
{description}

---
"""

    return final_text

def generate_knowledge_base():
    print("üß† Gerando base de conhecimento...")
    final_md = "# Base de Conhecimento ‚Äî Engenharia de Computa√ß√£o (UNOESC)\n\n"

    for page in PAGES:
        content = fetch_html(page)
        final_md += f"\n\n---\n## Conte√∫do extra√≠do de: {page}\n\n"
        final_md += content

    for pdf in PDF_LINKS:
        txt = fetch_pdf(pdf)
        if txt:
            final_md += f"## Fonte: {pdf}\n\n{txt}\n\n---\n"
        else:
            final_md += f"## Fonte: {pdf}\n\n*(Conte√∫do n√£o extra√≠do ‚Äî revis√£o manual necess√°ria)*\n\n---\n"

    ementario_md = fetch_ementario()
    final_md += "\n\n---\n## Ement√°rio Completo\n\n"
    final_md += ementario_md

    with open(OUTPUT_FILE, "w") as f:
        f.write(final_md)

    print(f"\n‚úÖ Base de conhecimento gerada em: {OUTPUT_FILE}")

if __name__ == "__main__":
    generate_knowledge_base()
